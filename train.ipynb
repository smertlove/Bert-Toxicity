{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8141dd13",
   "metadata": {},
   "source": [
    "## Установка зависимостей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c01bce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torch transformers scikit-learn datasets\n",
    "# !pip install 'accelerate>=0.26.0'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3f2e79",
   "metadata": {},
   "source": [
    "## Подготовка данных\n",
    "\n",
    "Будем заниматься задачей детекции токсичных комментариев. Данные у нас находятся в папке `data`. В файле `normal.txt` лежат обычные комментарии, в `toxic.txt` -- токсичные. Для тренировки модели надо собрать два разных набора: `X` и `y`. `X` Будет входом для модели. `y` будет переменной, которую хотим предсказать. В нашем случае `X` -- комментарий, а `y` -- метка 1 (комментарий токсичный) или 0 (комментарий обычный)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36d61491",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Комментарии у нас разделены двумя переносами строки\n",
    "# То есть чтобы получить список комментариев, нужно разделить даные по двум переносам строки\n",
    "# Открываем файл, читаем содержимое и разделяем по двум переносам\n",
    "normal_comments = (\n",
    "    open(\"data/normal.txt\")\n",
    "    .read()\n",
    "    .split(\"\\n\\n\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c878cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "toxic_comments = (\n",
    "    open(\"data/toxic.txt\")\n",
    "    .read()\n",
    "    .split(\"\\n\\n\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32e974ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8971, 4473)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Посмотрим, сколько у нас обычных и токсичных комментариев...\n",
    "len(normal_comments), len(toxic_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4f5b3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ...и сделаем для них метки!\n",
    "normal_labels = [0] * len(normal_comments)\n",
    "toxic_labels  = [1] * len(toxic_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be171c1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13444, 13444)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# И наконец соберем наши данные\n",
    "X = normal_comments + toxic_comments\n",
    "y = normal_labels + toxic_labels\n",
    "len(X), len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa4949bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Моя знакомая, лет 10 как не курит. Это всё при том, что муж как курил так и курит в квартире.(в вытяжку принудительную и мощную на кухне). Тянет до сих пор её иногда, сны снятся как вновь закурила, до сих пор то в жар бросает, то в холод из за тяги. Старается не выпивать алкогольные напитки, потому что желание взять снова сигарету, адски просто нарастает. Занимается йогой, пробежки по утрам, да и без дела не сидит чтоб хоть как то отвлечься..',\n",
       " 0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[13], y[13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c537d52c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(', мат. Мои нежные, девственные чувства оскорблены.', 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[12000], y[12000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2b79480",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Последнее, что здесь надо сделать -- это разделить данные на тренировочную и тестовую выборки.\n",
    "# Это нужно для того, чтобы понять, как модель работает на данных, которые она не видела во время обучения.\n",
    "# Для этого нам надо\n",
    "# 1) Перемешать наши данные \n",
    "#    (ведь сейчас у нас в самом начале всегда обычные комменты, а в конце -- токсичные.\n",
    "#    Модель нас не поймет во время тренировки)\n",
    "# 2) Разделить их в какой-то пропорции\n",
    "# Сделать всё это можно так:\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,   # Доля тестовой части\n",
    "    random_state=42, # Делаем рандом нерандомным, чтобы результаты всегда были одинаковые\n",
    "    shuffle=True     # И перемешиваем всё\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "959f48ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10755, 2689, 10755, 2689)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train), len(X_test), len(y_train), len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8be796c",
   "metadata": {},
   "source": [
    "## Подготовка модели\n",
    "\n",
    "В современном NLP обычно не нужно учить свою собственную модель прям с нуля. Существуют модели, предобученные (pretrained) для работы с естественным языком. Они долго учатся на огромных разнообразных массивах текста (речь о терабайтах), чтобы понять язык глобально. Идея в том, что потом эти знания можно переложить (transfer) на более узкую задачу, для которых данных сильно меньше. Мы именно это и сделаем: возьмем одну такую модель и дообучим (finetune) так, чтобы она понимала _концепт токсичности_.\n",
    "\n",
    "Существуют разные базовые модели, которые могут генерировать текст, переводить на разные языки, генерировать текст по картинке или картинку по тексту. В рамках нашей задачи нам нужна модель, которая _понимает_ язык, то есть принимает на вход текст и извлекает из него смысл. Для такой задачи используются модели класса \"кодировщик\" (encoder). Модель-кодировщик BERT или что-то вдохновленное им отлично подойдет.\n",
    "\n",
    "Мы возьмем [RuModernBERT от deepvk](https://huggingface.co/deepvk/RuModernBERT-base). Это самая свежая модель BERT для русского языка. Полный список всех моделей для разных задач и языков можно [посмотреть тут](https://huggingface.co/) порывшисть по поисковику."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2675bbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b2e5975e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Сначала надо определить, на каком устройстве будем учить и использовать модель.\n",
    "# Использовать видеокарту если она есть, иначе -- центральный процессор.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "76f03952",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/smertlove/sandbox/hse/dl/Bert-Toxicity/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2610a8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"deepvk/RuModernBERT-base\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c2dcf2a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at deepvk/RuModernBERT-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Мы не можем просто дать модели на вход текст. Нужно как-то уметь преобразровывать его в числа.\n",
    "# Поэтому все модели состоят из, собственно, модели,\n",
    "# и токенизатора -- штуки, которая разбивает входной текст на кусочки знакомым модели образом.\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d16b56a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenizer(\"Я — Батай, а ты — Лакан, Пойдём скорей плясать канкан.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9bcdcea0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[50281,\n",
       " 1128,\n",
       " 683,\n",
       " 3064,\n",
       " 5642,\n",
       " 18,\n",
       " 227,\n",
       " 147,\n",
       " 115,\n",
       " 1599,\n",
       " 683,\n",
       " 5245,\n",
       " 2367,\n",
       " 18,\n",
       " 926,\n",
       " 299,\n",
       " 34417,\n",
       " 35801,\n",
       " 9856,\n",
       " 24523,\n",
       " 436,\n",
       " 951,\n",
       " 1099,\n",
       " 20,\n",
       " 50282]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Вот так это выглядит\n",
    "tokens['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "694d9dc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS]Я — Батай, а ты — Лакан, Пойдём скорей плясать канкан.[SEP]'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# А тут видим, что токенизатор для модели добавляет в текст всякие прикольные штуки.\n",
    "tokenizer.decode(tokens['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "13f5733e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "from transformers import TrainingArguments, Trainer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c34b12f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 10755/10755 [00:01<00:00, 7687.41 examples/s]\n",
      "Map: 100%|██████████| 2689/2689 [00:00<00:00, 7018.05 examples/s]\n",
      "/tmp/ipykernel_23792/1013032888.py:54: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': None, 'bos_token_id': None}.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2019' max='2019' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2019/2019 18:58, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.231800</td>\n",
       "      <td>0.221361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.205900</td>\n",
       "      <td>0.210403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.180000</td>\n",
       "      <td>0.202807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.157400</td>\n",
       "      <td>0.201453</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2019, training_loss=0.24476644306740233, metrics={'train_runtime': 1138.7741, 'train_samples_per_second': 28.333, 'train_steps_per_second': 1.773, 'total_flos': 1.099455190170624e+16, 'train_loss': 0.24476644306740233, 'epoch': 3.0})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Тут готовим модель к дообучению.\n",
    "# Фактически тут диктант, который просто нужно уметь написать.\n",
    "# Всей интеллектуальной деятельностью, как ни странно, мы занимались выше.\n",
    "# (если это теперь увидит кто-то, меня на работу никуда не возьмут xdd)\n",
    "\n",
    "train_dataset = Dataset.from_dict({\n",
    "    'text': X_train,\n",
    "    'label': y_train\n",
    "})\n",
    "\n",
    "test_dataset = Dataset.from_dict({\n",
    "    'text': X_test,\n",
    "    'label': y_test\n",
    "})\n",
    "\n",
    "tokenize_function = lambda examples: tokenizer(\n",
    "    examples['text'],\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    max_length=512,\n",
    ")\n",
    "\n",
    "tokenized_train = train_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_test = test_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "model_params = list(model.base_model.parameters())\n",
    "\n",
    "# Замораживаем часть слоев модели\n",
    "for param in model_params:\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Размораживаем только последние слои\n",
    "for param in model_params[-6:]:  # Последние 6 слоев\n",
    "    param.requires_grad = True\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    eval_strategy=\"steps\",            # Оцениваем по шагам\n",
    "    eval_steps=500,                   # Каждые 500 шагов\n",
    "    logging_strategy=\"steps\",         # Логируем по шагам\n",
    "    logging_steps=100,                # Каждые 100 шагов\n",
    "    save_strategy=\"steps\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    greater_is_better=False,\n",
    "    logging_dir='./logs',\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_test,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af0476f",
   "metadata": {},
   "source": [
    "Ура! Что-то натренировалось.\n",
    "Цифры в табличке сверху показывают что модель каждый раз училась чему-то новому (Training loss  Validation loss стабильно падают).\n",
    "Возможно, стоило бы поучить ее еще немного, но для примера хватит."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4575df05",
   "metadata": {},
   "source": [
    "## Теперь можно пользоваться моделью)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6e5d7116",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271495e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Для удобства тут собираем модель в пайплайн, чтобы в одну команду проведить все операции\n",
    "classifier = pipeline(\n",
    "    \"text-classification\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "96b247c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'LABEL_1', 'score': 1.0}]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = classifier(\"Какая же ты падла блять\")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f8e95392",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'LABEL_0', 'score': 0.9736777544021606}]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = classifier(\"Я люблю маму и папу\")\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe66449",
   "metadata": {},
   "source": [
    "По-хорошему здесь еще должен быть замер качества и метрики accuracy, F1, roc-auc и пр., но это пока опустим. Цель данной тетрадки -- показать, что всё не так страшно, как может выглядеть на первый взгляд :)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87aab58",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
